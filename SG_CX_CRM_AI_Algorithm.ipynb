{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+UqHfzjSgP2aNUh9MVhCn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sourajitaghosh/CXAIAlgorithm/blob/main/SG_CX_CRM_AI_Algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "U2zJC3QqTR-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear Regression\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Create a sample dataset\n",
        "data = {'Past_Sales': [10000, 8000, 12000, 5000, 13000, 7000, 11000, 9000],\n",
        "        'Lead_Score': [78, 60, 88, 45, 92, 58, 82, 72]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the feature and target variables\n",
        "X = df[['Lead_Score']]\n",
        "y = df['Past_Sales']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print the intercept and coefficients\n",
        "print(\"Intercept:\", model.intercept_)\n",
        "print(\"Coefficients:\", model.coef_)\n",
        "\n",
        "# Evaluate the model performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the mean squared error and R-squared\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R-squared:\", r2)\n",
        "\n",
        "# Make a prediction for a new lead with a score of 80\n",
        "new_lead_score = 80\n",
        "predicted_sales = model.predict([[new_lead_score]])\n",
        "\n",
        "print(\"\\nPredicted sales for a lead with a score of\", new_lead_score, \":\", predicted_sales[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzHIVLU2R5GS",
        "outputId": "4f882f38-b35f-4f12-fb99-2dcbb7a144f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intercept: -2740.736383954827\n",
            "Coefficients: [167.2744383]\n",
            "Mean Squared Error: 248751.63285107174\n",
            "R-squared: 0.004993468595713035\n",
            "\n",
            "Predicted sales for a lead with a score of 80 : 10641.218680155274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "9VZQ3tq0ShHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LogisticRegression\n",
        "\n",
        "# Create a sample dataset\n",
        "data = {'Support_Tickets': [2, 0, 5, 1, 0, 4, 1, 3],\n",
        "        'Contract_Length': [12, 24, 12, 24, 36, 12, 24, 24],\n",
        "        'Churn': [1, 0, 1, 0, 0, 1, 0, 1]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the features and target variable\n",
        "X = df[['Support_Tickets', 'Contract_Length']]\n",
        "y = df['Churn']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a logistic regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print the model coefficients\n",
        "print(\"Coefficients:\", model.coef_)\n",
        "\n",
        "# Evaluate the model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy and confusion matrix\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix)\n",
        "\n",
        "# Predict churn for a new customer with 3 support tickets and a 12-month contract\n",
        "new_customer = [[3, 12]]\n",
        "predicted_churn = model.predict(new_customer)\n",
        "\n",
        "if predicted_churn == 1:\n",
        "  print(\"\\nPredicted churn for the new customer: Yes\")\n",
        "else:\n",
        "  print(\"\\nPredicted churn for the new customer: No\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCOXbQEHR-RA",
        "outputId": "191ffbdd-e049-4d4a-98a1-18bb68eb69e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [[ 0.84303606 -0.34402857]]\n",
            "Accuracy: 1.0\n",
            "Confusion Matrix:\n",
            " [[1 0]\n",
            " [0 1]]\n",
            "\n",
            "Predicted churn for the new customer: Yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree"
      ],
      "metadata": {
        "id": "5iB0bVSqtnCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Create a sample dataset\n",
        "data = {\n",
        "    'CustomerID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'Tenure': [12, 3, 24, 6, 18, 1, 36, 12, 2, 48],\n",
        "    'Monthly_Charges': [50, 70, 40, 60, 80, 90, 30, 50, 70, 60],\n",
        "    'Contract_Type': ['Monthly', 'Annual', 'Monthly', 'Monthly', 'Annual', 'Two-Year', 'Monthly', 'Monthly', 'Annual', 'Monthly'],\n",
        "    'Internet_Speed': ['Basic', 'Standard', 'Basic', 'Standard', 'Premium', 'Basic', 'Premium', 'Standard', 'Basic', 'Premium'],\n",
        "    'Tech_Support_Calls': [2, 1, 0, 3, 0, 4, 1, 2, 1, 0],\n",
        "    'Churn': [1, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Split data into features (X) and target variable (y)\n",
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Encoding for Categorical Data\n",
        "le = LabelEncoder()\n",
        "\n",
        "X_train['Contract_Type'] = le.fit_transform(X_train['Contract_Type'])\n",
        "X_test['Contract_Type'] = le.transform(X_test['Contract_Type'])\n",
        "\n",
        "X_train['Internet_Speed'] = le.fit_transform(X_train['Internet_Speed'])\n",
        "X_test['Internet_Speed'] = le.transform(X_test['Internet_Speed'])\n",
        "\n",
        "# Create a decision tree classifier\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train the decision tree model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix_result)\n",
        "\n",
        "classification_report_result = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", classification_report_result)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpC7gJmiSCK-",
        "outputId": "b85fd6d4-a04f-40dc-cb1d-0dae421b23a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0\n",
            "Confusion Matrix:\n",
            " [[0 2]\n",
            " [0 0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       2.0\n",
            "           1       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00       2.0\n",
            "   macro avg       0.00      0.00      0.00       2.0\n",
            "weighted avg       0.00      0.00      0.00       2.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machines (SVMs)"
      ],
      "metadata": {
        "id": "4osIMH39trT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Support Vector Machines (SVMs)\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Sample dataset (assuming numerical representation for categories)\n",
        "data = {'Category': [1, 2, 1, 0, 2, 1, 0, 2],\n",
        "        'Brand': [3, 1, 3, 2, 1, 3, 2, 1],\n",
        "        'Price': [100, 200, 150, 80, 250, 120, 90, 280],\n",
        "        'Purchased': [1, 0, 1, 0, 1, 1, 0, 1]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define features and target variable\n",
        "X = df[['Category', 'Brand', 'Price']]\n",
        "y = df['Purchased']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an SVM classifier model\n",
        "model = SVC(kernel='linear')  # Use linear kernel for interpretability\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "# Predict purchase probability for a new product (Category: 2, Brand: 2, Price: 180)\n",
        "new_product = [[2, 2, 180]]\n",
        "predicted_purchase = model.predict(new_product)\n",
        "\n",
        "if predicted_purchase == 1:\n",
        "  print(\"\\nPredicted purchase for the new product: High probability\")\n",
        "else:\n",
        "  print(\"\\nPredicted purchase for the new product: Low probability\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPIdRGW3SFIT",
        "outputId": "bf0cf463-317d-426a-aead-6e6a0be8824d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "Precision: 0.5\n",
            "Recall: 1.0\n",
            "\n",
            "Predicted purchase for the new product: High probability\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes"
      ],
      "metadata": {
        "id": "no4OjPTStt2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive Bayes\n",
        "import pandas as pd\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Sample dataset\n",
        "data = {'Age_Group': [1, 2, 0, 1, 2, 3, 0, 1],\n",
        "        'Income_Level': [2, 0, 1, 2, 0, 3, 1, 2],\n",
        "        'Website_Visits': ['High', 'Medium', 'High', 'Low', 'Medium', 'Low', 'High', 'Medium'],\n",
        "        'Purchase_Frequency': ['High', 'Low', 'Medium', 'High', 'Low', 'High', 'Low', 'Medium'],\n",
        "        'Customer_Segment': ['High_Value', 'Budget_Conscious', 'Frequent_Buyer', 'High_Value', 'Budget_Conscious', 'Frequent_Buyer', 'Budget_Conscious', 'Frequent_Buyer']}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Encode categorical features\n",
        "le = LabelEncoder()\n",
        "df['Website_Visits'] = le.fit_transform(df['Website_Visits'])\n",
        "df['Purchase_Frequency'] = le.fit_transform(df['Purchase_Frequency'])\n",
        "df['Customer_Segment'] = le.fit_transform(df['Customer_Segment'])\n",
        "\n",
        "# Define features and target variable\n",
        "X = df[['Age_Group', 'Income_Level', 'Website_Visits', 'Purchase_Frequency']]\n",
        "y = df['Customer_Segment']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Multinomial Naive Bayes classifier model\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy and classification report\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# Predict customer segment for a new customer (Age_Group: 2, Income_Level: 1, Website_Visits: Medium, Purchase_Frequency: High)\n",
        "new_customer = [[2, 1, 1, 2]]  # Encoded values for ['Medium', 'High']\n",
        "predicted_segment = model.predict(new_customer)[0]\n",
        "print(\"\\nPredicted customer segment for the new customer:\", predicted_segment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqzoBtibSItz",
        "outputId": "6354a34e-7978-4ff5-e5c7-ab4dfc06d275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.33      0.33      0.33         2\n",
            "weighted avg       0.50      0.50      0.50         2\n",
            "\n",
            "\n",
            "Predicted customer segment for the new customer: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MultinomialNB was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Nearest Neighbors (KNN)"
      ],
      "metadata": {
        "id": "HH61psW-txjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#K-Nearest Neighbors (KNN)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample dataset\n",
        "data = {'Industry': ['Tech', 'Retail', 'Tech', 'Healthcare', 'Retail', 'Finance', 'Tech', 'Healthcare'],\n",
        "        'Company_Size': [100, 500, 200, 1000, 250, 700, 300, 500],\n",
        "        'Website_Pages_Visited': ['Product', 'Pricing', 'Contact', 'Product', 'About_Us', 'Contact', 'Product', 'Blog'],\n",
        "        'Converted_Lead': [1, 0, 1, 1, 0, 0, 1, 0]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert categorical columns to object data type\n",
        "df['Industry'] = df['Industry'].astype('object')\n",
        "df['Website_Pages_Visited'] = df['Website_Pages_Visited'].astype('object')\n",
        "\n",
        "# One-hot encode categorical features\n",
        "df = pd.get_dummies(df, columns=['Industry', 'Website_Pages_Visited'])\n",
        "\n",
        "# Define features and target variable\n",
        "X = df.drop('Converted_Lead', axis=1)  # Exclude target column\n",
        "y = df['Converted_Lead']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a KNN classifier model (choose appropriate k value through experimentation)\n",
        "model = KNeighborsClassifier(n_neighbors=5)  # Number of neighbors to consider\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy and confusion matrix\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix_result)\n",
        "\n",
        "# Predict conversion for a new lead (Industry: Tech, Company_Size: 400, Website_Pages_Visited: Contact)\n",
        "new_lead = [[1, 0, 0, 400, 0, 0, 0, 0, 1, 0]]  # One-hot encoded features\n",
        "predicted_conversion = model.predict(new_lead)[0]\n",
        "\n",
        "if predicted_conversion == 1:\n",
        "    print(\"\\nPredicted conversion for the new lead: Yes (Qualified Lead)\")\n",
        "else:\n",
        "    print(\"\\nPredicted conversion for the new lead: No (Not Qualified Lead)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj7GdzI7SPoS",
        "outputId": "d9f9e421-cd6a-429e-83af-1628dc8e53fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0\n",
            "Confusion Matrix:\n",
            " [[0 2]\n",
            " [0 0]]\n",
            "\n",
            "Predicted conversion for the new lead: Yes (Qualified Lead)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KMeans"
      ],
      "metadata": {
        "id": "2NOTqyLetzjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#KMeans\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {'Support_Tickets': [5, 2, 10, 1, 3, 7, 4, 9],\n",
        "        'Product_A_Usage': ['High', 'Low', 'High', 'Medium', 'Medium', 'Low', 'High', 'Medium'],\n",
        "        'Product_B_Usage': ['Low', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium', 'High']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# One-hot encode categorical features\n",
        "df = pd.get_dummies(df, columns=['Product_A_Usage', 'Product_B_Usage'])\n",
        "\n",
        "# Define features\n",
        "X = df\n",
        "\n",
        "# Choose the number of clusters (often done through experimentation)\n",
        "k = 3\n",
        "\n",
        "# Create a K-means clustering model\n",
        "model = KMeans(n_clusters=k, random_state=42)\n",
        "\n",
        "# Train the model (fit the data to the clusters)\n",
        "model.fit(X)\n",
        "\n",
        "# Get cluster labels for each data point\n",
        "cluster_labels = model.labels_\n",
        "\n",
        "# Evaluate the model performance using Silhouette Score (higher score indicates better cluster separation)\n",
        "silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "print(\"Silhouette Score:\", silhouette_avg)\n",
        "\n",
        "# Print cluster labels for the first 5 customers\n",
        "print(\"Customer Cluster Labels (First 5):\", cluster_labels[:5])\n",
        "\n",
        "# Example: Assigning a new customer to a cluster (assuming data is available)\n",
        "# One-hot encoded features for product usage: Support_Tickets, Product_A_Usage_High, Product_A_Usage_Low, Product_A_Usage_Medium, Product_B_Usage_High, Product_B_Usage_Low, Product_B_Usage_Medium\n",
        "new_customer = [[2, 1, 0, 0, 1, 0, 0]]  # Example values, you may need to adjust based on your new customer's actual data\n",
        "predicted_cluster = model.predict(new_customer)[0]\n",
        "print(\"\\nPredicted Cluster for the New Customer:\", predicted_cluster)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1iV-RUySSk8",
        "outputId": "b538aba3-8b77-4c31-aaf9-f07fe3a5b64b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score: 0.3542257810333593\n",
            "Customer Cluster Labels (First 5): [0 2 1 2 2]\n",
            "\n",
            "Predicted Cluster for the New Customer: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but KMeans was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "Dn66aNlZt2DT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import pandas as pd\n",
        "\n",
        "# Sample dataset (assuming numerical representation for categories)\n",
        "data = {'Age': [25, 32, 40, 22, 38, 55, 28, 42],\n",
        "        'Income': [50000, 70000, 60000, 40000, 80000, 90000, 45000, 75000],\n",
        "        'Purchase_Frequency': ['High', 'Medium', 'Low', 'High', 'Low', 'Medium', 'High', 'Medium'],\n",
        "        'Support_Interaction': ['No', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'No'],\n",
        "        'Churn': ['No', 'Yes', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# One-hot encode categorical features\n",
        "df = pd.get_dummies(df, columns=['Purchase_Frequency', 'Support_Interaction', 'Churn'])\n",
        "\n",
        "# Define features and target variable\n",
        "X = df.drop(['Churn_No', 'Churn_Yes'], axis=1)  # Exclude target columns\n",
        "y = df['Churn_Yes']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Random Forest classifier model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)  # Choose number of trees (experiment for best value)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])  # Probability of churn class\n",
        "\n",
        "# Print the accuracy and ROC AUC score\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"ROC AUC Score:\", roc_auc)\n",
        "\n",
        "# Predict churn probability for a new customer (Age: 35, Income: 65000, Purchase_Frequency: Medium, Support_Interaction: No)\n",
        "# One-hot encoded features: Age, Income, Purchase_Frequency_High, Purchase_Frequency_Low, Purchase_Frequency_Medium, Support_Interaction_No, Support_Interaction_Yes\n",
        "new_customer = [[35, 65000, 0, 0, 1, 1, 0]]  # Example values, you may need to adjust based on your new customer's actual data\n",
        "predicted_churn_prob = model.predict_proba(new_customer)[0][1]\n",
        "\n",
        "if predicted_churn_prob > 0.5:\n",
        "    print(\"\\nPredicted churn probability for the new customer: High\")\n",
        "else:\n",
        "    print(\"\\nPredicted churn probability for the new customer: Low\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWxh29BBSV9g",
        "outputId": "ff527e70-3b32-466c-f8f5-c13dcd03958a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "ROC AUC Score: 1.0\n",
            "\n",
            "Predicted churn probability for the new customer: High\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA Principal Component Analysis"
      ],
      "metadata": {
        "id": "HQPSi6gft4fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA Principal Component Analysis\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_squared_error  # Example metric\n",
        "\n",
        "# Sample dataset (assuming numerical representation for categories)\n",
        "data = {'Category': [1, 2, 1, 0, 2, 1, 0, 2],\n",
        "        'Brand': [3, 1, 3, 2, 1, 3, 2, 1],\n",
        "        'Price': [100, 200, 150, 80, 250, 120, 90, 280],\n",
        "        'Technical_Spec_1': [5, 7, 4, 8, 3, 6, 2, 9],\n",
        "        'Technical_Spec_2': [20, 15, 25, 18, 12, 22, 10, 19]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define features\n",
        "X = df\n",
        "\n",
        "# Create a PCA model (choose the number of components based on explained variance ratio)\n",
        "pca = PCA(n_components=2)  # Experiment to find the optimal number\n",
        "\n",
        "# Fit the model on the data\n",
        "pca.fit(X)\n",
        "\n",
        "# Transform the data to the lower-dimensional space\n",
        "X_reduced = pca.transform(X)\n",
        "\n",
        "# Example: Calculate similarity between two products (indices 0 and 2) using Euclidean distance\n",
        "product1 = X_reduced[0]\n",
        "product2 = X_reduced[2]\n",
        "similarity = np.linalg.norm(product1 - product2)\n",
        "print(\"Similarity between product 0 and product 2:\", similarity)\n",
        "\n",
        "# Evaluation (replace with relevant metrics for your use case)\n",
        "# Example: Use Mean Squared Error (MSE) to evaluate reconstruction accuracy on unseen data\n",
        "X_reconstructed = pca.inverse_transform(X_reduced)\n",
        "mse = mean_squared_error(X, X_reconstructed)\n",
        "print(\"Mean Squared Error (reconstruction accuracy):\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyotH2xUSY5K",
        "outputId": "6f3d590e-4304-474e-80a2-10961831b7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between product 0 and product 2: 50.18727723778562\n",
            "Mean Squared Error (reconstruction accuracy): 0.8213745339702827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting"
      ],
      "metadata": {
        "id": "U8IFwat7t8_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gradient Boosting\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "\n",
        "# Sample dataset (assuming numerical representation for categories)\n",
        "data = {'Age': [25, 32, 40, 22, 38, 55, 28, 42],\n",
        "        'Income': [50000, 70000, 60000, 40000, 80000, 90000, 45000, 75000],\n",
        "        'Purchase_Frequency': ['High', 'Medium', 'Low', 'High', 'Low', 'Medium', 'High', 'Medium'],\n",
        "        'Avg_Purchase_Value': [100, 150, 80, 120, 200, 250, 90, 180],\n",
        "        'CLTV': [2000, 3500, 1200, 2800, 5000, 7000, 1500, 4200]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# One-hot encode categorical features\n",
        "df = pd.get_dummies(df, columns=['Purchase_Frequency'])  # One-hot encode categorical features\n",
        "\n",
        "# Define features and target variable\n",
        "X = df.drop('CLTV', axis=1)\n",
        "y = df['CLTV']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Gradient Boosting Regressor model\n",
        "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)  # Adjust parameters as needed\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "# Predict CLTV for a new customer (Age: 35, Income: 65000, Purchase_Frequency: Medium, Avg_Purchase_Value: 130)\n",
        "# One-hot encoded features: Age, Income, Purchase_Frequency_High, Purchase_Frequency_Low, Purchase_Frequency_Medium, Avg_Purchase_Value\n",
        "new_customer = [[35, 65000, 0, 0, 1, 130]]  # One-hot encoded features\n",
        "predicted_cltv = model.predict(new_customer)[0]\n",
        "print(\"\\nPredicted CLTV for the new customer:\", predicted_cltv)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fqPspJwScGv",
        "outputId": "ef4fea10-032f-4d09-b19f-e43f9adac26e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 3232392.043819775\n",
            "\n",
            "Predicted CLTV for the new customer: 1200.0441439033088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FK0ywRrgSfJc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}